{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "from numpy.linalg import svd\n",
    "from util import nextplot, plot_xy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probabilistic PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this method.\n",
    "def ppca_gen(N=10000, D=2, L=2, sigma2=0.5, mu=None, lambda_=None, Q=None, seed=None):\n",
    "    \"\"\"Generate data from a given PPCA model.\n",
    "\n",
    "    Unless specified otherwise, uses a fixed mean, fixed eigenvalues (variances along\n",
    "    principal components), and a random orthogonal eigenvectors (principal components).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # determine model parameters (from arguments or default)\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    if mu is None:\n",
    "        mu = np.arange(D) + 1.0\n",
    "    if Q is None:\n",
    "        Q = scipy.stats.ortho_group.rvs(D)\n",
    "    if lambda_ is None:\n",
    "        lambda_ = np.arange(D, 0, -1) * 2\n",
    "\n",
    "    # weight matrix is determined from first L eigenvectors and eigenvalues of\n",
    "    # covariance matrix\n",
    "    Q_L = Q[:, :L]\n",
    "    lambda_L = lambda_[:L]\n",
    "    W = Q_L * np.sqrt(lambda_L)  # scales columns\n",
    "\n",
    "    # generate data\n",
    "    Z = np.random.randn(N, L)  # latent variables\n",
    "    Eps = np.random.randn(N, D) * np.sqrt(sigma2)  # noise\n",
    "    X = Z @ W.transpose() + mu + Eps  # data points\n",
    "\n",
    "    # all done\n",
    "    return dict(\n",
    "        N=N, D=D, L=L, X=X, Z=Z, mu=mu, Q_L=Q_L, lambda_L=lambda_L, W=W, Eps=Eps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this method.\n",
    "def ppca_plot_2d(data, X=\"X\", mu=\"mu\", W=\"W\", alpha=0.05, axis=None, **kwargs):\n",
    "    \"\"\"Plot 2D PPCA data along with its weight vectors.\"\"\"\n",
    "    if not axis:\n",
    "        nextplot()\n",
    "        axis = plt.gca()\n",
    "    X = data[X] if isinstance(X, str) else X\n",
    "    plot_xy(X[:, 0], X[:, 1], alpha=alpha, axis=axis, **kwargs)\n",
    "\n",
    "    # additional plot elements: mean and components\n",
    "    if mu is not None:\n",
    "        mu = data[mu] if isinstance(mu, str) else mu\n",
    "        if W is not None:\n",
    "            W = data[W] if isinstance(W, str) else W\n",
    "            head_width = np.linalg.norm(W[:, 0]) / 10.0\n",
    "            for j in range(W.shape[1]):\n",
    "                axis.arrow(\n",
    "                    mu[0],\n",
    "                    mu[1],\n",
    "                    W[0, j],\n",
    "                    W[1, j],\n",
    "                    length_includes_head=True,\n",
    "                    head_width=head_width,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate and plot a toy dataset\n",
    "toy_ppca = ppca_gen(L=1, sigma2=0.5, seed=0)\n",
    "ppca_plot_2d(toy_ppca)\n",
    "print(np.sum(toy_ppca[\"X\"] ** 3))  # must be 253376.52003073416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impact of noise\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppca_mle(X, L):\n",
    "    \"\"\"Computes the ML estimates of PPCA model parameters.\n",
    "\n",
    "    Returns a dictionary with keys `mu`, `W`, and `sigma2` and the corresponding ML\n",
    "    estimates as values.\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    # Compute the ML estimates of the PPCA model parameters: mu_mle, sigma2_mle (based\n",
    "    # on mu_mle), and W_mle (based on mu_mle and sigma2_mle). In your code, only use\n",
    "    # standard matrix/vector operations and svd(...).\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return dict(mu=mu_mle, W=W_mle, sigma2=sigma2_mle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': array([0.96499135, 1.99411338]),\n",
    "#  'W': array([[-1.92216075], [-0.42851619]]),\n",
    "#  'sigma2': 0.5021816994668619}\n",
    "ppca_mle(toy_ppca[\"X\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': array([0.96499135, 1.99411338]),\n",
    "#  'W': array([[-2.0428184 ,  0.15419681], [-0.45541495, -0.6916683 ]]),\n",
    "#  'sigma2': 0.0}\n",
    "ppca_mle(toy_ppca[\"X\"], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) Negative Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppca_nll(X, model):\n",
    "    \"\"\"Compute the negative log-likelihood for the given data.\n",
    "\n",
    "    Model is a dictionary containing keys \"mu\", \"sigma2\" and \"W\" (as produced by\n",
    "    `ppca_mle` above).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce: 32320.62982368089\n",
    "ppca_nll(toy_ppca[\"X\"], ppca_mle(toy_ppca[\"X\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Discover the Secret!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the secret data\n",
    "X = np.loadtxt(\"data/secret_ppca.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine a suitable choice of L using a scree plot.\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine a suitable choice of L using validation data.\n",
    "split = len(X) * 3 // 4\n",
    "X_train = X[:split,]\n",
    "X_valid = X[split:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this function.\n",
    "def gmm_gen(N, mu, pi, Sigma=None, seed=None):\n",
    "    \"\"\"Generate data from a given GMM model.\n",
    "\n",
    "    `N` is the number of data points to generate. `mu` and `Sigma` are lists with `K`\n",
    "    elements holding the mean and covariance matrix of each mixture component. `pi` is a\n",
    "    `K`-dimensional probability vector of component sizes.\n",
    "\n",
    "    If `Sigma` is unspecified, a default (random) choice is taken.\n",
    "    \"\"\"\n",
    "    K = len(pi)\n",
    "    D = len(mu[0])\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    if Sigma is None:\n",
    "        Sigma = [\n",
    "            Q.transpose() @ np.diag([(k + 1) ** 2, k + 1]) @ Q\n",
    "            for k, Q in enumerate([scipy.stats.ortho_group.rvs(2) for k in range(K)])\n",
    "        ]\n",
    "\n",
    "    components = np.random.choice(range(K), p=pi, size=N)\n",
    "    X = np.zeros([N, D])\n",
    "    for k in range(K):\n",
    "        indexes = components == k\n",
    "        N_k = np.sum(indexes.astype(np.int))\n",
    "        if N_k == 0:\n",
    "            continue\n",
    "\n",
    "        dist = scipy.stats.multivariate_normal(mean=mu[k], cov=Sigma[k])\n",
    "        X[indexes, :] = dist.rvs(size=N_k)\n",
    "\n",
    "    return dict(X=X, components=components, mu=mu, Sigma=Sigma, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a toy dataset and plot it.\n",
    "toy_gmm = gmm_gen(\n",
    "    10000,\n",
    "    [\n",
    "        np.array([0, 0]),\n",
    "        np.array([10, 0]),\n",
    "        np.array([-10, 0]),\n",
    "        np.array([0, 10]),\n",
    "        np.array([0, -10]),\n",
    "    ],\n",
    "    np.array([0.1, 0.2, 0.25, 0.1, 0.35]),\n",
    "    seed=4,\n",
    ")\n",
    "\n",
    "print(np.sum(toy_gmm[\"X\"] ** 3))  # must be -4217163.292239752\n",
    "\n",
    "plot_xy(toy_gmm[\"X\"][:, 0], toy_gmm[\"X\"][:, 1], toy_gmm[\"components\"], alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit 5 clusters using k-means.\n",
    "kmeans = KMeans(5).fit(toy_gmm[\"X\"])\n",
    "plot_xy(toy_gmm[\"X\"][:, 0], toy_gmm[\"X\"][:, 1], kmeans.labels_, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c) Fit a GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmm_e(X, model, return_F=False):\n",
    "    \"\"\"Perform the E step of EM for a GMM (MLE estimate).\n",
    "\n",
    "    `model` is a dictionary holding model parameters (keys `mu`, `Sigma`, and `pi`\n",
    "    defined as in `gmm_gen`).\n",
    "\n",
    "    Returns a NxK matrix of cluster membership probabilities. If `return_F` is true,\n",
    "    also returns an NxK matrix holding the density of each data point (row) for each\n",
    "    component (column).\n",
    "\n",
    "    \"\"\"\n",
    "    mu, Sigma, pi = model[\"mu\"], model[\"Sigma\"], model[\"pi\"]\n",
    "    N, D = X.shape\n",
    "    K = len(pi)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # all done\n",
    "    if return_F:\n",
    "        return W, F\n",
    "    else:\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# (array([[1.00000000e+000, 8.27699923e-031, 2.34110986e-067,\n",
    "#          4.10467740e-110, 3.93734426e-160],\n",
    "#         [9.99999954e-001, 4.61690063e-008, 5.65425711e-019,\n",
    "#          3.33201883e-033, 8.33882728e-052],\n",
    "#         [1.00000000e+000, 1.86295657e-011, 1.28430390e-026,\n",
    "#          5.94329943e-046, 1.62944956e-070]]),\n",
    "#  array([[1.02589878e-027, 3.39654536e-058, 1.60116117e-094,\n",
    "#          2.10549177e-137, 1.34643889e-187],\n",
    "#         [7.37197125e-008, 1.36142641e-015, 2.77886819e-026,\n",
    "#          1.22817741e-040, 2.04911993e-059],\n",
    "#         [2.13229824e-010, 1.58895161e-021, 1.82567931e-036,\n",
    "#          6.33644347e-056, 1.15815748e-080]]))\n",
    "dummy_model = dict(\n",
    "    mu=[np.array([k, k + 1]) for k in range(5)],\n",
    "    Sigma=[np.array([[3, 1], [1, 2]]) / (k + 1) for k in range(5)],\n",
    "    pi=np.array([0.1, 0.25, 0.15, 0.2, 0.3]),\n",
    ")\n",
    "gmm_e(toy_gmm[\"X\"][:3,], dummy_model, return_F=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmm_m(X, W):\n",
    "    \"\"\"Perform the M step of EM for a GMM (MLE estimate).\n",
    "\n",
    "    `W` is the NxK cluster membership matrix computed in the E step. Returns a new model\n",
    "    (dictionary with keys `mu`, `Sigma`, and `pi` defined as in `gmm_gen`).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    K = W.shape[1]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return dict(mu=mu, Sigma=Sigma, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': [array([-6.31351787, -3.07275642]),\n",
    "#   array([-8.76676837, -2.34516689]),\n",
    "#   array([-2.08994533, -8.92768065])],\n",
    "#  'Sigma': [array([[ 16.51718982, -22.89694189],\n",
    "#          [-22.89694189,  31.74086835]]), array([[ 13.62163617, -13.69361772],\n",
    "#          [-13.69361772,  16.07669971]]), array([[ 18.4992526 , -25.64457491],\n",
    "#          [-25.64457491,  35.54977255]])],\n",
    "#  'pi': array([0.13333333, 0.53333333, 0.33333333])}\n",
    "gmm_m(toy_gmm[\"X\"][:3,], np.array([[0.1, 0.2, 0.7], [0.3, 0.4, 0.3], [0.0, 1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you do not need to modify this method\n",
    "def gmm_fit(X, K, max_iter=100, mu0=None, Sigma0=None, pi0=None, gmm_m=gmm_m):\n",
    "    \"\"\"Fit a GMM model using EM.\n",
    "\n",
    "    `K` refers to the number of mixture components to fit. `mu0`, `Sigma0`, and `pi0`\n",
    "    are initial parameters (automatically set when unspecified).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    if mu0 is None:\n",
    "        mu0 = [np.random.randn(D) for k in range(K)]\n",
    "    if Sigma0 is None:\n",
    "        Sigma0 = [np.eye(D) * 10 for k in range(K)]\n",
    "    if pi0 is None:\n",
    "        pi0 = np.ones(K) / K\n",
    "\n",
    "    model = dict(mu=mu0, Sigma=Sigma0, pi=pi0)\n",
    "    for it in range(max_iter):\n",
    "        W = gmm_e(X, model)\n",
    "        model = gmm_m(X, W)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d+2e) Experiment with GMMs for the toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit on toy data and color each point by most likely component. Also try fitting with 4\n",
    "# or 6 components.\n",
    "toy_gmm_fit = gmm_fit(toy_gmm[\"X\"], 5)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2f) Discover the Secret (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the secret data.\n",
    "X = np.loadtxt(\"data/secret_gmm.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many components are hidden in this data?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
